{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimSent.indexer.index_builder import IndexBuilder\n",
    "from SimSent.vectorizer.sentence_vectorizer import SentenceVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: /Users/lukasferrer/Documents/SimSent/SimSent/vectorizer/model/1fb57c3ffe1a38479233ee9853ddd7a8ac8a8c47/\n",
      "Initializing TF Session...\n"
     ]
    }
   ],
   "source": [
    "sv = SentenceVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path('TestProject002/')\n",
    "ibdr = IndexBuilder(project_dir, sentence_vectorizer=sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TestProject002/sample_news_2019-03-05.tsv',\n",
       " 'TestProject002/sample_news_2019-03-04.tsv',\n",
       " 'TestProject002/sample_news_2019-03-06.tsv']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('TestProject002/*.tsv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in files:\n",
    "#     ibdr.tsv_to_index(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0425 12:04:21.913794 4554524096 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import os.path as p\n",
    "import glob\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from sqlitedict import SqliteDict\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from SimSent.vectorizer.sentence_vectorizer import DockerVectorizer\n",
    "from SimSent.indexer.deploy_handler import RangeShards\n",
    "from SimSent.indexer.faiss_cache import faiss_cache\n",
    "\n",
    "project_dir = Path('TestProject002/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SimSent.server.service_handler import QueryHandler\n",
    "\n",
    "# class QueryProcessor:\n",
    "#     QueryReturn = np.array\n",
    "#     DiffScores = List[np.float32]\n",
    "#     VectorIDs = List[np.int64]\n",
    "#     FaissSearch = Tuple[DiffScores, VectorIDs]\n",
    "#     FormattedSearch = List[Tuple[np.int64, np.float32, str]]\n",
    "#     FormattedMultiSearch = Dict[str, FormattedSearch]\n",
    "\n",
    "#     def __init__(self, query_vectorizer: object, index_handler: object, \n",
    "#                  project_dir: Path, nested: bool = False):\n",
    "#         super().__init__()\n",
    "#         self.vectorizer = query_vectorizer\n",
    "#         self.indexer = index_handler\n",
    "        \n",
    "#         # Get id-to-sent maps\n",
    "#         get = '*/*.sqlite' if nested else '*.sqlite'\n",
    "#         db_files = glob.glob(p.abspath(project_dir/get))\n",
    "#         self.sent_dbs = dict()\n",
    "#         for f in db_files:\n",
    "#             self.sent_dbs[Path(f).stem] = SqliteDict(f)\n",
    "\n",
    "#     @faiss_cache(32)\n",
    "#     def query_corpus(self, query_str: str, keys: List[str], \n",
    "#                      k: int = 5, radius: float = 1.0, verbose: bool = True\n",
    "#                      ) -> FormattedMultiSearch:\n",
    "#         \"\"\"\n",
    "#         Vectorize query -> Search faiss index handler -> Format doc payload.\n",
    "#         Expects to receive only one query per call.\n",
    "#         \"\"\"\n",
    "#         # Vectorize\n",
    "#         t_v = time()\n",
    "#         query_vector = self.vectorize(query_str)\n",
    "\n",
    "#         # Search\n",
    "#         t_s = time()\n",
    "#         results = self.indexer.search(query_vector, keys, radius=radius)\n",
    "\n",
    "#         t_p = time()\n",
    "#         top_hits = list()\n",
    "#         similar_docs = dict()\n",
    "#         for source, result_set in results.items():\n",
    "#             sorted_set = self.format_results(source, result_set, k)\n",
    "#             top_hits.extend(sorted_set)\n",
    "#             similar_docs[source] = sorted_set\n",
    "#         similar_docs['top_hits'] = sorted(top_hits)[:k]\n",
    "\n",
    "#         t_r = time()\n",
    "#         if verbose:\n",
    "#             print(f'  Query vectorized in --- {t_s - t_v:0.4f}s')\n",
    "#             print(f'  Index searched in ----- {t_p - t_s:0.4f}s')\n",
    "#             print(f'  Payload formatted in -- {t_r - t_p:0.4f}s\\n')\n",
    "\n",
    "#         return similar_docs\n",
    "\n",
    "#     def vectorize(self, query: Union[str, List[str]]) -> QueryReturn:\n",
    "#         \"\"\"\n",
    "#         Use DockerVectorizer for fast Query Vectorization.\n",
    "#         :param query: Text to vectorize\n",
    "#         :return: Formatted query embedding\n",
    "#         \"\"\"\n",
    "#         if not isinstance(query, list):\n",
    "#             query = [query]\n",
    "#         if len(query) > 1:\n",
    "#             query = query[:1]\n",
    "\n",
    "#         query_vector = self.vectorizer.make_vectors(query)\n",
    "\n",
    "#         if isinstance(query_vector[0], list):\n",
    "#             query_vector = np.array(query_vector, dtype=np.float32)\n",
    "#         return query_vector\n",
    "\n",
    "#     def format_results(self, source: str, result_set: FaissSearch, k: int\n",
    "#                        ) -> FormattedSearch:\n",
    "#         scores, hit_ids = result_set\n",
    "#         sents = list()\n",
    "#         for sent_id in hit_ids:\n",
    "#             sents.append(self.sent_dbs[source][str(sent_id)])\n",
    "        \n",
    "#         return sorted(zip(scores, hit_ids, sents))[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DockerVectorizer()\n",
    "rs = RangeShards(project_dir, nprobe=32, get_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QueryHandler(dv, rs, project_dir=project_dir, nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_news_2019-03-04', 'sample_news_2019-03-05', 'sample_news_2019-03-06']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(rs.shards.keys())\n",
    "# keys = [keys[0].replace('_mmap', '_id-sent-map')]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Query vectorized in --- 0.0116s\n",
      "  Index searched in ----- 0.0151s\n",
      "  Payload formatted in -- 0.5390s\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sample_news_2019-03-04': [(0.56036913, 6714, '\"This has to change.'),\n",
       "  (0.6461661, 12448, 'GOOD)'),\n",
       "  (0.6461661, 12462, ': GOOD)'),\n",
       "  (0.6805541, 1645, 'This should be the main principle.'),\n",
       "  (0.72779745, 6750, 'Not So Fast!')],\n",
       " 'sample_news_2019-03-05': [(0.47615832, 17447, 'This need not be so.'),\n",
       "  (0.5374373, 21146, \"Well I wouldn't go that far.\"),\n",
       "  (0.54418623, 21663, 'This is simply absurd.'),\n",
       "  (0.5450684, 20566, 'We probably should look at it.'),\n",
       "  (0.5803312,\n",
       "   15196,\n",
       "   \"If that idea makes you a little queasy, you aren't the only one.\")],\n",
       " 'sample_news_2019-03-06': [(0.36795262,\n",
       "   15989,\n",
       "   \"It makes things interesting, and that's a good thing.\"),\n",
       "  (0.36795262, 16177, \"It makes things interesting, and that's a good thing.\"),\n",
       "  (0.43312803, 5959, \"This is ridiculous, isn't it?!\"),\n",
       "  (0.4512312, 4748, \"It's a shame.\"),\n",
       "  (0.4547708, 6115, \"I mean, it's really...\")],\n",
       " 'top_hits': [(0.36795262,\n",
       "   15989,\n",
       "   \"It makes things interesting, and that's a good thing.\"),\n",
       "  (0.36795262, 16177, \"It makes things interesting, and that's a good thing.\"),\n",
       "  (0.43312803, 5959, \"This is ridiculous, isn't it?!\"),\n",
       "  (0.4512312, 4748, \"It's a shame.\"),\n",
       "  (0.4547708, 6115, \"I mean, it's really...\")]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qp.query_corpus('This is a bad thing', keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.sent_dbs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.shards[keys[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SimSent",
   "language": "python",
   "name": "simsent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
